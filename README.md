# TrainAI Data Annotation & Evaluation Portfolio

This repository demonstrates my hands-on practice in AI data annotation,
AI output evaluation, content moderation, and dataset quality assurance,
aligned with human-in-the-loop AI workflows.

## Projects Included
- Text annotation for sentiment and intent classification
- AI-generated response evaluation using quality rubrics
- Content moderation based on safety and ethical guidelines
- Dataset quality checks for consistency and bias

These samples reflect my ability to follow guidelines, apply consistent
judgment, and support high-quality AI training tasks.
